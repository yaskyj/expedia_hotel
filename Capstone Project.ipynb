{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import ml_metrics as metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn import ensemble\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, RFECV, SelectFromModel\n",
    "from sklearn import tree\n",
    "#from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_dtypes = {'date_time': pd.np.object,\n",
    "'site_name': pd.np.int64,\n",
    "'posa_continent': pd.np.int64,\n",
    "'user_location_country': pd.np.int64,\n",
    "'user_location_region': pd.np.int64,\n",
    "'user_location_city': pd.np.int64,\n",
    "'orig_destination_distance': pd.np.float64,\n",
    "'user_id': pd.np.int64,\n",
    "'is_mobile': pd.np.int64,\n",
    "'is_package': pd.np.int64,\n",
    "'channel': pd.np.int64,\n",
    "'srch_ci': pd.np.object,\n",
    "'srch_co': pd.np.object,\n",
    "'srch_adults_cnt': pd.np.int64,\n",
    "'srch_children_cnt': pd.np.int64,\n",
    "'srch_rm_cnt': pd.np.int64,\n",
    "'srch_destination_id': pd.np.int64,\n",
    "'srch_destination_type_id': pd.np.int64,\n",
    "'is_booking': pd.np.int64,\n",
    "'cnt': pd.np.int64,\n",
    "'hotel_continent': pd.np.int64,\n",
    "'hotel_country': pd.np.int64,\n",
    "'hotel_market': pd.np.int64,\n",
    "'hotel_cluster': pd.np.int64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_train = pd.read_csv('train.csv', dtype=train_dtypes, iterator=True, chunksize=1000)\n",
    "all_train = pd.concat([chunk[chunk['is_booking'] == 1] for chunk in all_train], ignore_index=True)\n",
    "# all_train = pd.concat(all_train, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_train['id'] = [i for i in range(0, len(all_train))]\n",
    "all_train['orig_destination_distance'] = all_train['orig_destination_distance'].fillna(-1)\n",
    "all_train['date_time'] = pd.to_datetime(all_train['date_time'], errors='coerce')\n",
    "all_train['srch_ci'] = pd.to_datetime(all_train['srch_ci'], errors='coerce')\n",
    "all_train['srch_co'] = pd.to_datetime(all_train['srch_co'], errors='coerce')\n",
    "all_train['activity_month'] = all_train['date_time'].fillna(-1).dt.month.astype(int)\n",
    "all_train['activity_year'] = all_train['date_time'].fillna(-1).dt.year.astype(int)\n",
    "all_train['activity_dow'] = all_train['date_time'].fillna(-1).dt.dayofweek.astype(int)\n",
    "all_train['activity_day'] = all_train['date_time'].fillna(-1).dt.day.astype(int)\n",
    "all_train['activity_quarter'] = all_train['date_time'].fillna(-1).dt.quarter.astype(int)\n",
    "all_train['checkin_month'] = all_train['srch_ci'].fillna(-1).dt.month.astype(int)\n",
    "all_train['checkin_year'] = all_train['srch_ci'].fillna(-1).dt.year.astype(int)\n",
    "all_train['checkin_dow'] = all_train['srch_ci'].fillna(-1).dt.dayofweek.astype(int)\n",
    "all_train['checkin_day'] = all_train['srch_ci'].fillna(-1).dt.day.astype(int)\n",
    "all_train['checkin_quarter'] = all_train['srch_ci'].fillna(-1).dt.quarter.astype(int)\n",
    "all_train['checkout_month'] = all_train['srch_co'].fillna(-1).dt.month.astype(int)\n",
    "all_train['checkout_year'] = all_train['srch_co'].fillna(-1).dt.year.astype(int)\n",
    "all_train['checkout_dow'] = all_train['srch_co'].fillna(-1).dt.dayofweek.astype(int)\n",
    "all_train['checkout_day'] = all_train['srch_co'].fillna(-1).dt.day.astype(int)\n",
    "all_train['checkout_quarter'] = all_train['srch_co'].fillna(-1).dt.quarter.astype(int)\n",
    "all_train['stay_length'] = (all_train['srch_co'] - all_train['srch_ci']).astype(int)\n",
    "#Split groups into two different classifiers for destinations vs. no destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "destinations = pd.read_csv('destinations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "destination_ids = destinations['srch_destination_id']\n",
    "destinations_reduced = destinations.drop(['srch_destination_id'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pca = PCA(n_components=11, whiten=True)\n",
    "#pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pca.fit(destinations_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "destinations_reduced = pca.fit_transform(destinations_reduced)\n",
    "destinations_reduced = pd.DataFrame(destinations_reduced)\n",
    "destinations_reduced['srch_destination_id'] = destination_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_train = pd.merge(all_train, destinations_reduced, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_train.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "features = [c for c in all_train.columns if c not in ['id', 'is_booking', 'cnt', 'hotel_cluster', 'date_time', 'srch_ci', 'srch_co']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(all_train[features], all_train['hotel_cluster'], test_size=0.50)\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features_train, labels_train, test_size=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = ensemble.ExtraTreesClassifier(min_samples_split=500)\n",
    "clf = clf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "features_train = model.transform(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# forest = ensemble.RandomForestClassifier(min_samples_split=500)\n",
    "# selector = RFECV(forest, step=1, cv=5)\n",
    "# selector = selector.fit(features_train, labels_train)\n",
    "# selector.support_ \n",
    "# selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "forest = ensemble.RandomForestClassifier(min_samples_split=500)\n",
    "forest.fit(features_train, labels_train)\n",
    "# parameters = {'n_estimators':[10, 20], 'max_depth':[5, 10], 'min_samples_split':[250, 500]}\n",
    "# search = GridSearchCV(forest, parameters, n_jobs=1)\n",
    "# search.fit(features_train, labels_train)\n",
    "# clf.fit(all_train.drop(['id', 'is_booking', 'cnt', 'user_id', 'hotel_cluster', 'date_time', 'srch_ci', 'srch_co'], 1), all_train['hotel_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "features_test = model.transform(features_test)\n",
    "pred_probs = pd.DataFrame(forest.predict_proba(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#pred = pd.DataFrame([list([r.nlargest(5).index]) for i,r in pred_probs.iterrows()])\n",
    "pred = pd.DataFrame([list([r.sort_values(ascending=False)[:5].index.values]) for i,r in pred_probs.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print mapk([[l] for l in labels_test], pred.values, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "#clf = LogisticRegression(tol=0.1)\n",
    "#clf = GaussianNB()\n",
    "#clf_with = ensemble.AdaBoostClassifier().fit(with_features, with_labels.values.ravel())\n",
    "#clf_wo = ensemble.AdaBoostClassifier().fit(wo_features, wo_labels.values.ravel())\n",
    "#clf = ensemble.AdaBoostClassifier(SVC(probability=True, kernel='linear'),n_estimators=10)\n",
    "#clf = ensemble.GradientBoostingClassifier(SVC(probability=True, kernel='linear'),n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "#clf = ensemble.GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0, verbose=3)\n",
    "# clf_with = tree.DecisionTreeClassifier(min_samples_split=100).fit(with_features, with_labels.values.ravel())\n",
    "# clf_wo = tree.DecisionTreeClassifier(min_samples_split=50).fit(wo_features, wo_labels.values.ravel())\n",
    "# clf_with = ensemble.RandomForestClassifier(n_estimators=100, max_depth=5).fit(with_features, with_labels.values.ravel())\n",
    "# clf_wo = ensemble.RandomForestClassifier(n_estimators=20, min_samples_split=500, n_jobs=2).fit(wo_features, wo_labels.values.ravel())\n",
    "#clf - BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# with_dest_match = pd.merge(all_train, destinations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# wo_dest_match = all_train[~(all_train.id.isin(with_dest_match.id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# with_features = with_dest_match.drop(['id', 'is_booking', 'cnt', 'user_id', 'hotel_cluster', 'date_time', 'srch_ci', 'srch_co'],1)\n",
    "# with_labels = with_dest_match['hotel_cluster']\n",
    "# wo_features = wo_dest_match.drop(['id', 'is_booking', 'cnt', 'user_id', 'hotel_cluster', 'date_time', 'srch_ci', 'srch_co'],1)\n",
    "# wo_labels = wo_dest_match['hotel_cluster']\n",
    "# with_features = with_features.reindex_axis(sorted(with_features.columns), axis=1)\n",
    "# wo_features = wo_features.reindex_axis(sorted(wo_features.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all_scores = []\n",
    "# %%time\n",
    "# for i in range(0, 20):\n",
    "#     features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=0.5)\n",
    "#     clf = tree.DecisionTreeClassifier(min_samples_split=500)\n",
    "#     clf = clf.fit(features_train, labels_train.values.ravel())\n",
    "#     pred_probs = pd.DataFrame(clf.predict_proba(features_test))\n",
    "#     pred_probs = pd.DataFrame([list([r.sort_values(ascending=False)[:3].index.values]) for i,r in pred_probs.iterrows()])\n",
    "#     labels_test_df = pd.DataFrame(labels_test.values, index=range(0, len(labels_test)))\n",
    "#     test_score = mapk(labels_test_df.values, pred_probs.values)\n",
    "#     all_scores.append(test_score)\n",
    "# print np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_score = mapk(labels_test_df.values, pred_probs.values)\n",
    "print test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_dtypes = {'id': pd.np.int64,\n",
    "'date_time': pd.np.object,\n",
    "'site_name': pd.np.int64,\n",
    "'posa_continent': pd.np.int64,\n",
    "'user_location_country': pd.np.int64,\n",
    "'user_location_region': pd.np.int64,\n",
    "'user_location_city': pd.np.int64,\n",
    "'orig_destination_distance': pd.np.float64,\n",
    "'user_id': pd.np.int64,\n",
    "'is_mobile': pd.np.int64,\n",
    "'is_package': pd.np.int64,\n",
    "'channel': pd.np.int64,\n",
    "'srch_ci': pd.np.object,\n",
    "'srch_co': pd.np.object,\n",
    "'srch_adults_cnt': pd.np.int64,\n",
    "'srch_children_cnt': pd.np.int64,\n",
    "'srch_rm_cnt': pd.np.int64,\n",
    "'srch_destination_id': pd.np.int64,\n",
    "'srch_destination_type_id': pd.np.int64,\n",
    "'hotel_continent': pd.np.int64,\n",
    "'hotel_country': pd.np.int64,\n",
    "'hotel_market': pd.np.int64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_test = pd.read_csv('test.csv', dtype=test_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_test['orig_destination_distance'] = all_test['orig_destination_distance'].fillna(-1)\n",
    "all_test['date_time'] = pd.to_datetime(all_test['date_time'], errors='coerce')\n",
    "all_test['srch_ci'] = pd.to_datetime(all_test['srch_ci'], errors='coerce')\n",
    "all_test['srch_co'] = pd.to_datetime(all_test['srch_co'], errors='coerce')\n",
    "all_test['activity_month'] = all_test['date_time'].fillna(-1).dt.month.astype(int)\n",
    "all_test['activity_year'] = all_test['date_time'].fillna(-1).dt.year.astype(int)\n",
    "all_test['activity_dow'] = all_test['date_time'].fillna(-1).dt.dayofweek.astype(int)\n",
    "all_test['activity_day'] = all_test['date_time'].fillna(-1).dt.day.astype(int)\n",
    "all_test['activity_quarter'] = all_test['date_time'].fillna(-1).dt.quarter.astype(int)\n",
    "all_test['checkin_month'] = all_test['srch_ci'].fillna(-1).dt.month.astype(int)\n",
    "all_test['checkin_year'] = all_test['srch_ci'].fillna(-1).dt.year.astype(int)\n",
    "all_test['checkin_dow'] = all_test['srch_ci'].fillna(-1).dt.dayofweek.astype(int)\n",
    "all_test['checkin_day'] = all_test['srch_ci'].fillna(-1).dt.day.astype(int)\n",
    "all_test['checkin_quarter'] = all_test['srch_ci'].fillna(-1).dt.quarter.astype(int)\n",
    "all_test['checkout_month'] = all_test['srch_co'].fillna(-1).dt.month.astype(int)\n",
    "all_test['checkout_year'] = all_test['srch_co'].fillna(-1).dt.year.astype(int)\n",
    "all_test['checkout_dow'] = all_test['srch_co'].fillna(-1).dt.dayofweek.astype(int)\n",
    "all_test['checkout_day'] = all_test['srch_co'].fillna(-1).dt.day.astype(int)\n",
    "all_test['checkout_quarter'] = all_test['srch_co'].fillna(-1).dt.quarter.astype(int)\n",
    "all_test['stay_length'] = (all_test['srch_co'] - all_test['srch_ci']).astype(int)\n",
    "#Split groups into two different classifiers for destinations vs. no destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_test = pd.merge(all_test, destinations_reduced, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_test.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_features = all_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_probs = pd.DataFrame(forest.predict_proba(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#pred = pd.DataFrame([list([r.nlargest(5).index]) for i,r in pred_probs.iterrows()])\n",
    "test_pred = pd.DataFrame([list([r.sort_values(ascending=False)[:5].index.values]) for i,r in test_probs.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = all_test['id']\n",
    "submission['hotel_cluster'] = [' '.join(str(x) for x in y) for y in test_pred.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.sort_values(by='id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
